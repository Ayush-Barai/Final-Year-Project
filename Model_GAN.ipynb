{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Kaggle for dataset access\n",
        "!pip install -q kaggle\n",
        "\n",
        "# TensorFlow (already installed in Colab, but just in case)\n",
        "!pip install -q tensorflow\n",
        "\n",
        "# tqdm for progress bars\n",
        "!pip install -q tqdm\n",
        "\n",
        "# matplotlib for image visualization\n",
        "!pip install -q matplotlib\n",
        "\n",
        "# PIL for image processing (included in `Pillow`)\n",
        "!pip install -q Pillow\n",
        "\n",
        "!pip install opencv-python-headless"
      ],
      "metadata": {
        "id": "8BvLJGMQORPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Upload your kaggle.json\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d chinafax/cfpw-dataset"
      ],
      "metadata": {
        "id": "YC1m-WX6OOoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip cfpw-dataset.zip -d dataset"
      ],
      "metadata": {
        "id": "Y9Cu_HDyOaUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjjNVYmNOJ_U"
      },
      "outputs": [],
      "source": [
        "# Face Frontalization using G-GAN on CFPW Dataset (Colab-Compatible)\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set image size and constants\n",
        "IMG_HEIGHT, IMG_WIDTH = 128, 128\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "\n",
        "# Load and preprocess dataset\n",
        "import glob\n",
        "import random\n",
        "\n",
        "def load_image_pair(profile_path, frontal_path):\n",
        "    profile_img = Image.open(profile_path).resize((128, 128)).convert('RGB')\n",
        "    frontal_img = Image.open(frontal_path).resize((128, 128)).convert('RGB')\n",
        "    profile_img = ((np.array(profile_img).astype(np.float32)) / 127.5) - 1.0\n",
        "    frontal_img = ((np.array(frontal_img).astype(np.float32)) / 127.5) - 1.0\n",
        "\n",
        "    return profile_img, frontal_img\n",
        "\n",
        "def load_dataset_pairs(base_path):\n",
        "    profile_images = []\n",
        "    frontal_images = []\n",
        "\n",
        "    person_dirs = glob.glob(os.path.join(base_path, '*'))\n",
        "    for person_dir in tqdm(person_dirs):\n",
        "        profile_imgs = sorted(glob.glob(os.path.join(person_dir, 'profile', '*.jpg')))\n",
        "        frontal_imgs = sorted(glob.glob(os.path.join(person_dir, 'frontal', '*.jpg')))\n",
        "\n",
        "        min_len = min(len(profile_imgs), len(frontal_imgs))\n",
        "        for i in range(min_len):\n",
        "            prof, fron = load_image_pair(profile_imgs[i], frontal_imgs[i])\n",
        "            profile_images.append(prof)\n",
        "            frontal_images.append(fron)\n",
        "\n",
        "    return np.array(profile_images), np.array(frontal_images)\n",
        "\n",
        "# Load paired data\n",
        "profile_imgs, frontal_imgs = load_dataset_pairs('/content/dataset/cfp-dataset/Data/Images')\n",
        "\n",
        "# Create TensorFlow dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((profile_imgs, frontal_imgs)).shuffle(10000).batch(BATCH_SIZE)\n",
        "\n",
        "\n",
        "# Build Generator (Encoder + Decoder)\n",
        "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, BatchNormalization, ReLU, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def build_generator(input_shape=(128, 128, 3)):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = inputs\n",
        "\n",
        "    # Encoder with Dropout after some layers\n",
        "    for i, filters in enumerate([16, 32, 64, 128, 256, 512,1024]):\n",
        "        x = Conv2D(filters, kernel_size=4, strides=2, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "        if i >= 3:  # Apply dropout from the 4th layer onwards (128 and deeper)\n",
        "            x = Dropout(0.3)(x)\n",
        "\n",
        "    # Decoder with Dropout after some layers\n",
        "    for i, filters in enumerate([ 512, 256, 128, 64, 32, 16]):\n",
        "        x = Conv2DTranspose(filters, kernel_size=4, strides=2, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "        if i < 3:  # Apply dropout to first few decoder layers (closest to bottleneck)\n",
        "            x = Dropout(0.3)(x)\n",
        "\n",
        "    # Final output layer\n",
        "    x = Conv2DTranspose(3, kernel_size=4, strides=2, padding='same', activation='tanh')(x)\n",
        "    return Model(inputs, x, name=\"G_GAN_Generator_With_Dropout\")\n",
        "\n",
        "# Build Discriminator\n",
        "\n",
        "def build_discriminator(input_shape=(128, 128, 3)):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for filters in [16, 32, 64, 128, 256, 512]:\n",
        "        x = Conv2D(filters, kernel_size=3, strides=2, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "    return Model(inputs, x, name=\"G_GAN_Discriminator\")\n",
        "\n",
        "# Define custom loss function\n",
        "def combined_gan_loss(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "\n",
        "    l1 = tf.reduce_mean(tf.square(y_true - y_pred))  # MSE\n",
        "    l2 = tf.reduce_mean(tf.abs(y_true - y_pred))     # MAE\n",
        "    l3 = tf.reduce_mean(tf.square(y_true - y_pred))  # Again MSE, per paper's formula\n",
        "\n",
        "    return 0.001 * l1 + 1.0 * l2 + 1.0 * l3\n",
        "\n",
        "# Instantiate models\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "# Optimizers\n",
        "g_optimizer = Adam(0.0002, beta_1=0.5)\n",
        "d_optimizer = Adam(0.0002, beta_1=0.5)\n",
        "\n",
        "# Binary cross-entropy loss\n",
        "bce = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "# Training step\n",
        "@tf.function\n",
        "def train_step(profile_images, real_frontal_images):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        generated_frontal = generator(profile_images, training=True)\n",
        "\n",
        "        real_output = discriminator(real_frontal_images, training=True)\n",
        "        fake_output = discriminator(generated_frontal, training=True)\n",
        "\n",
        "        d_loss_real = bce(tf.ones_like(real_output), real_output)\n",
        "        d_loss_fake = bce(tf.zeros_like(fake_output), fake_output)\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "        g_loss_gan = bce(tf.ones_like(fake_output), fake_output)\n",
        "        g_loss_custom = combined_gan_loss(real_frontal_images, generated_frontal)\n",
        "        g_total_loss = g_loss_gan + g_loss_custom\n",
        "\n",
        "    gradients_of_generator = tape.gradient(g_total_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = tape.gradient(d_loss, discriminator.trainable_variables)\n",
        "\n",
        "    g_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    d_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return d_loss, g_total_loss\n",
        "\n",
        "# Training loop\n",
        "def train(dataset, epochs):\n",
        "    best_g_loss = float('inf')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        for profile_batch, frontal_batch in dataset:\n",
        "            d_loss, g_loss = train_step(profile_batch, frontal_batch)\n",
        "\n",
        "        print(f\"Discriminator Loss: {d_loss.numpy():.4f}, Generator Loss: {g_loss.numpy():.4f}\")\n",
        "\n",
        "        # Save best model based on generator loss\n",
        "        if g_loss < best_g_loss:\n",
        "            best_g_loss = g_loss\n",
        "            generator.save('/content/drive/MyDrive/GGAN_Models_E400/best_generator.h5')\n",
        "            print(\"🔁 Saved best generator (g_loss improved).\")\n",
        "\n",
        "\n",
        "\n",
        "# Save sample images\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    predictions = model(test_input, training=False)\n",
        "    predictions = (predictions + 1) / 2.0\n",
        "    fig = plt.figure(figsize=(8, 2))\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(1, 4, i+1)\n",
        "        plt.imshow(predictions[i])\n",
        "        plt.axis('off')\n",
        "    plt.savefig(f\"image_at_epoch_{epoch}.png\")\n",
        "    plt.close()\n",
        "\n",
        "# Start training\n",
        "train(dataset, EPOCHS)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set generator to evaluation mode (in Keras, this is done implicitly)\n",
        "def visualize_generated_images(generator, profile_images, num_samples=4):\n",
        "    profile_images = profile_images[:num_samples]\n",
        "\n",
        "    generated_images = generator(profile_images, training=False)\n",
        "    generated_images = (generated_images + 1.0) / 2.0  # De-normalize to [0, 1]\n",
        "    profile_images = (profile_images + 1.0) / 2.0\n",
        "\n",
        "    plt.figure(figsize=(num_samples * 2, 4))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        # Show original profile image\n",
        "        plt.subplot(2, num_samples, i + 1)\n",
        "        plt.imshow(profile_images[i])\n",
        "        plt.title(\"Profile\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Show generated frontal image\n",
        "        plt.subplot(2, num_samples, i + 1 + num_samples)\n",
        "        plt.imshow(generated_images[i])\n",
        "        plt.title(\"Generated Front\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "qFRaeL1dOerc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample 4 test images from dataset\n",
        "sample_profiles = profile_imgs[:4]\n",
        "\n",
        "# Visualize results\n",
        "visualize_generated_images(generator, sample_profiles, num_samples=4)\n"
      ],
      "metadata": {
        "id": "BHNAnAyMOfiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create a directory in your Drive (once)\n",
        "save_path = '/content/drive/MyDrive/GGAN_Models'\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Save generator\n",
        "generator.save(os.path.join(save_path, 'ggan_generator.h5'))\n",
        "\n",
        "# Optional: Save discriminator\n",
        "discriminator.save(os.path.join(save_path, 'ggan_discriminator.h5'))"
      ],
      "metadata": {
        "id": "smAA_BQrO0sz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}